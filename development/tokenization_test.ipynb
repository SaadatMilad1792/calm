{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03e858ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "## -- libraries and packages -- ########################################################################################\n",
    "########################################################################################################################\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from calm import tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d912477",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "## -- sample pararaphs for pretraining tokenizer and validating it -- ##################################################\n",
    "########################################################################################################################\n",
    "tr_text = \"\"\"The sun dipped below the horizon, casting long shadows across the quiet town. Birds chirped their evening songs, and the gentle rustle of leaves filled the air. In the distance, the faint hum of a passing train echoed through the streets, blending with the soft murmur of conversations from open windows. Lanterns flickered to life, illuminating cobblestone paths and the faces of people winding down their day. Even in the stillness, there was a sense of anticipation, as if the night held secrets waiting to be discovered.\"\"\"\n",
    "va_text = \"\"\"The library was nearly empty, its tall shelves stretching into dimly lit aisles that smelled faintly of old paper and dust. A single desk lamp glowed in the corner where a student scribbled furiously into a notebook, the sound of pen scratching mixing with the occasional creak of the wooden floor. Outside, rain tapped steadily against the windows, a soft percussion that made the silence inside even heavier. Somewhere deep in the stacks, a book thudded shut, as if reminding anyone listening that the night was far from over.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1b00068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original text: The library was nearly empty, its tall shelves stretching into dimly lit aisles that smelled faintly of old paper and dust. A single desk lamp glowed in the corner where a student scribbled furiously into a notebook, the sound of pen scratching mixing with the occasional creak of the wooden floor. Outside, rain tapped steadily against the windows, a soft percussion that made the silence inside even heavier. Somewhere deep in the stacks, a book thudded shut, as if reminding anyone listening that the night was far from over.\n",
      "tokens extracted: [84, 104, 256, 108, 105, 98, 114, 97, 114, 121, 32, 119, 97, 261, 110, 101, 97, 114, 108, 121, 32, 101, 109, 112, 116, 121, 269, 313, 115, 257, 97, 108, 108, 278, 104, 290, 118, 101, 261, 265, 114, 282, 99, 104, 270, 259, 116, 111, 32, 277, 109, 108, 121, 32, 108, 105, 287, 97, 105, 115, 302, 115, 258, 276, 278, 109, 290, 108, 264, 32, 304, 259, 116, 108, 121, 307, 111, 108, 100, 32, 112, 97, 112, 274, 32, 300, 32, 100, 117, 265, 275, 65, 278, 263, 283, 100, 101, 115, 107, 32, 108, 97, 109, 112, 32, 103, 108, 268, 264, 32, 259, 260, 99, 111, 114, 110, 274, 32, 119, 104, 274, 256, 97, 32, 265, 117, 100, 266, 116, 278, 99, 114, 105, 98, 98, 108, 264, 32, 102, 117, 114, 105, 111, 117, 115, 108, 121, 32, 259, 116, 111, 32, 97, 32, 110, 111, 116, 101, 98, 111, 111, 107, 44, 260, 115, 111, 117, 110, 100, 307, 112, 266, 278, 99, 114, 276, 99, 104, 270, 109, 105, 120, 270, 119, 313, 104, 260, 111, 99, 99, 97, 115, 105, 262, 97, 108, 32, 99, 114, 101, 97, 107, 32, 267, 260, 119, 111, 111, 100, 266, 32, 102, 108, 111, 111, 114, 275, 79, 117, 116, 115, 105, 100, 101, 269, 114, 97, 259, 257, 97, 112, 288, 32, 265, 101, 97, 277, 108, 121, 32, 97, 103, 97, 259, 265, 260, 319, 279, 299, 97, 278, 267, 287, 112, 274, 99, 117, 281, 105, 262, 258, 276, 32, 109, 97, 100, 256, 116, 104, 256, 115, 285, 266, 99, 256, 259, 115, 105, 100, 256, 101, 298, 32, 104, 101, 97, 118, 105, 274, 275, 83, 111, 109, 101, 119, 104, 274, 256, 100, 101, 101, 112, 32, 259, 311, 97, 99, 107, 299, 97, 289, 111, 111, 107, 258, 117, 100, 100, 264, 278, 104, 117, 116, 269, 97, 261, 105, 102, 32, 114, 101, 109, 259, 312, 272, 121, 262, 256, 108, 105, 265, 266, 263, 258, 276, 260, 110, 105, 310, 287, 119, 97, 284, 97, 114, 32, 102, 280, 109, 32, 111, 316, 46]\n",
      "decoded tokens: The library was nearly empty, its tall shelves stretching into dimly lit aisles that smelled faintly of old paper and dust. A single desk lamp glowed in the corner where a student scribbled furiously into a notebook, the sound of pen scratching mixing with the occasional creak of the wooden floor. Outside, rain tapped steadily against the windows, a soft percussion that made the silence inside even heavier. Somewhere deep in the stacks, a book thudded shut, as if reminding anyone listening that the night was far from over.\n",
      "\n",
      "original text length: 528 length after tokenization: 363\n",
      "generated pairs: {(101, 32): 256, (32, 116): 257, (257, 104): 258, (105, 110): 259, (258, 256): 260, (115, 32): 261, (111, 110): 262, (259, 103): 263, (101, 100): 264, (115, 116): 265, (101, 110): 266, (111, 102): 267, (111, 119): 268, (44, 32): 269, (263, 32): 270, (105, 114): 271, (97, 110): 272, (267, 32): 273, (101, 114): 274, (46, 32): 275, (97, 116): 276, (100, 105): 277, (32, 115): 278, (100, 268): 279, (114, 111): 280, (115, 115): 281, (101, 116): 282, (108, 256): 283, (261, 102): 284, (105, 108): 285, (285, 108): 286, (116, 32): 287, (112, 264): 288, (32, 98): 289, (101, 108): 290, (104, 111): 291, (262, 269): 292, (262, 103): 293, (261, 97): 294, (258, 101): 295, (295, 271): 296, (296, 32): 297, (118, 266): 298, (115, 269): 299, (272, 100): 300, (300, 260): 301, (108, 101): 302, (99, 101): 303, (102, 97): 304, (287, 104): 305, (117, 109): 306, (32, 273): 307, (263, 257): 308, (101, 99): 309, (103, 104): 310, (260, 265): 311, (100, 270): 312, (105, 116): 313, (109, 117): 314, (314, 114): 315, (118, 274): 316, (276, 105): 317, (111, 112): 318, (119, 259): 319}\n",
      "validation results: True\n"
     ]
    }
   ],
   "source": [
    "########################################################################################################################\n",
    "## -- pretraining the tokenizer, and validating encoder and decoder performance -- #####################################\n",
    "########################################################################################################################\n",
    "tokenizer = tokenization.Tokenizer(tr_text)\n",
    "tokenizer.max_vocab_size = tokenizer.base_vocab_size + 64\n",
    "tokenizer.generate_vocab()\n",
    "\n",
    "print(\"original text:\", va_text)\n",
    "tokens = tokenizer.encoder(va_text)\n",
    "print(\"tokens extracted:\", tokens)\n",
    "new_text = tokenizer.decoder(tokens)\n",
    "print(\"decoded tokens:\", new_text, end = \"\\n\\n\")\n",
    "\n",
    "print(\"original text length:\", len(va_text), \"length after tokenization:\", len(tokens))\n",
    "print(\"generated pairs:\", tokenizer. new_merged_indexes)\n",
    "print(\"validation results:\", va_text == tokenizer.decoder(tokenizer.encoder(va_text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74aa9bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original text: The library was nearly empty, its tall shelves stretching into dimly lit aisles that smelled faintly of old paper and dust. A single desk lamp glowed in the corner where a student scribbled furiously into a notebook, the sound of pen scratching mixing with the occasional creak of the wooden floor. Outside, rain tapped steadily against the windows, a soft percussion that made the silence inside even heavier. Somewhere deep in the stacks, a book thudded shut, as if reminding anyone listening that the night was far from over.\n",
      "tokens extracted: [84, 104, 256, 108, 105, 98, 114, 97, 114, 121, 32, 119, 97, 261, 110, 101, 97, 114, 108, 121, 32, 101, 109, 112, 116, 121, 269, 313, 115, 257, 97, 108, 108, 278, 104, 290, 118, 101, 261, 265, 114, 282, 99, 104, 270, 259, 116, 111, 32, 277, 109, 108, 121, 32, 108, 105, 287, 97, 105, 115, 302, 115, 258, 276, 278, 109, 290, 108, 264, 32, 304, 259, 116, 108, 121, 307, 111, 108, 100, 32, 112, 97, 112, 274, 32, 300, 32, 100, 117, 265, 275, 65, 278, 263, 283, 100, 101, 115, 107, 32, 108, 97, 109, 112, 32, 103, 108, 268, 264, 32, 259, 260, 99, 111, 114, 110, 274, 32, 119, 104, 274, 256, 97, 32, 265, 117, 100, 266, 116, 278, 99, 114, 105, 98, 98, 108, 264, 32, 102, 117, 114, 105, 111, 117, 115, 108, 121, 32, 259, 116, 111, 32, 97, 32, 110, 111, 116, 101, 98, 111, 111, 107, 44, 260, 115, 111, 117, 110, 100, 307, 112, 266, 278, 99, 114, 276, 99, 104, 270, 109, 105, 120, 270, 119, 313, 104, 260, 111, 99, 99, 97, 115, 105, 262, 97, 108, 32, 99, 114, 101, 97, 107, 32, 267, 260, 119, 111, 111, 100, 266, 32, 102, 108, 111, 111, 114, 275, 79, 117, 116, 115, 105, 100, 101, 269, 114, 97, 259, 257, 97, 112, 288, 32, 265, 101, 97, 277, 108, 121, 32, 97, 103, 97, 259, 265, 260, 319, 279, 299, 97, 278, 267, 287, 112, 274, 99, 117, 281, 105, 262, 258, 276, 32, 109, 97, 100, 256, 116, 104, 256, 115, 285, 266, 99, 256, 259, 115, 105, 100, 256, 101, 298, 32, 104, 101, 97, 118, 105, 274, 275, 83, 111, 109, 101, 119, 104, 274, 256, 100, 101, 101, 112, 32, 259, 311, 97, 99, 107, 299, 97, 289, 111, 111, 107, 258, 117, 100, 100, 264, 278, 104, 117, 116, 269, 97, 261, 105, 102, 32, 114, 101, 109, 259, 312, 272, 121, 262, 256, 108, 105, 265, 266, 263, 258, 276, 260, 110, 105, 310, 287, 119, 97, 284, 97, 114, 32, 102, 280, 109, 32, 111, 316, 46]\n",
      "decoded tokens: The library was nearly empty, its tall shelves stretching into dimly lit aisles that smelled faintly of old paper and dust. A single desk lamp glowed in the corner where a student scribbled furiously into a notebook, the sound of pen scratching mixing with the occasional creak of the wooden floor. Outside, rain tapped steadily against the windows, a soft percussion that made the silence inside even heavier. Somewhere deep in the stacks, a book thudded shut, as if reminding anyone listening that the night was far from over.\n",
      "\n",
      "original text length: 528 length after tokenization: 363\n",
      "generated pairs: {(101, 32): 256, (32, 116): 257, (257, 104): 258, (105, 110): 259, (258, 256): 260, (115, 32): 261, (111, 110): 262, (259, 103): 263, (101, 100): 264, (115, 116): 265, (101, 110): 266, (111, 102): 267, (111, 119): 268, (44, 32): 269, (263, 32): 270, (105, 114): 271, (97, 110): 272, (267, 32): 273, (101, 114): 274, (46, 32): 275, (97, 116): 276, (100, 105): 277, (32, 115): 278, (100, 268): 279, (114, 111): 280, (115, 115): 281, (101, 116): 282, (108, 256): 283, (261, 102): 284, (105, 108): 285, (285, 108): 286, (116, 32): 287, (112, 264): 288, (32, 98): 289, (101, 108): 290, (104, 111): 291, (262, 269): 292, (262, 103): 293, (261, 97): 294, (258, 101): 295, (295, 271): 296, (296, 32): 297, (118, 266): 298, (115, 269): 299, (272, 100): 300, (300, 260): 301, (108, 101): 302, (99, 101): 303, (102, 97): 304, (287, 104): 305, (117, 109): 306, (32, 273): 307, (263, 257): 308, (101, 99): 309, (103, 104): 310, (260, 265): 311, (100, 270): 312, (105, 116): 313, (109, 117): 314, (314, 114): 315, (118, 274): 316, (276, 105): 317, (111, 112): 318, (119, 259): 319}\n",
      "validation results: True\n"
     ]
    }
   ],
   "source": [
    "########################################################################################################################\n",
    "## -- loading the pretrained tokenizer, and validating encoder and decoder performance -- ##############################\n",
    "########################################################################################################################\n",
    "tokenizer = tokenization.Tokenizer()\n",
    "tokenizer.load_state(\"../data/vocab/tokenizer_state.pkl\")\n",
    "\n",
    "print(\"original text:\", va_text)\n",
    "tokens = tokenizer.encoder(va_text)\n",
    "print(\"tokens extracted:\", tokens)\n",
    "new_text = tokenizer.decoder(tokens)\n",
    "print(\"decoded tokens:\", new_text, end = \"\\n\\n\")\n",
    "\n",
    "print(\"original text length:\", len(va_text), \"length after tokenization:\", len(tokens))\n",
    "print(\"generated pairs:\", tokenizer. new_merged_indexes)\n",
    "print(\"validation results:\", va_text == tokenizer.decoder(tokenizer.encoder(va_text)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CompactAiLanguageModel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
